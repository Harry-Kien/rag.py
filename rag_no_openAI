import streamlit as st
import os
import shutil
import time
import psutil
from langchain_community.document_loaders import PyPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import Chroma
from langchain.embeddings import HuggingFaceEmbeddings
from langchain.docstore.document import Document

# -------------- ƒê·ªãnh nghƒ©a ƒë∆∞·ªùng d·∫´n -------------- #
CHROMA_PATH = "chroma"
DATA_PATH = "data"
DOCUMENT_TXT_PATH = "document.txt"  # ƒê∆∞·ªùng d·∫´n ƒë·∫øn file document.txt

# -------------- H√†m Embedding -------------- #
def get_embedding_function():
    return HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")

# -------------- Load d·ªØ li·ªáu t·ª´ th∆∞ m·ª•c v√† file document.txt -------------- #
def load_documents():
    docs = []
    
    # ƒê·ªçc n·ªôi dung t·ª´ file document.txt (n·∫øu t·ªìn t·∫°i)
    if os.path.exists(DOCUMENT_TXT_PATH):
        with open(DOCUMENT_TXT_PATH, "r", encoding="utf-8") as f:
            content = f.read()
        docs.append(Document(page_content=content))
    
    # ƒê·ªçc c√°c file PDF trong th∆∞ m·ª•c data
    if os.path.exists(DATA_PATH):
        for file in os.listdir(DATA_PATH):
            file_path = os.path.join(DATA_PATH, file)
            if file.endswith(".pdf"):
                loader = PyPDFLoader(file_path)
                docs.extend(loader.load())
    
    return docs

# -------------- Chia nh·ªè t√†i li·ªáu -------------- #
def split_documents(documents):
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=128, chunk_overlap=20)
    return text_splitter.split_documents(documents)

# -------------- T·∫°o ho·∫∑c l·∫•y VectorStore -------------- #
def create_or_get_vectorstore():
    embedding_function = get_embedding_function()
    if os.path.exists(CHROMA_PATH) and os.listdir(CHROMA_PATH):
        db = Chroma(persist_directory=CHROMA_PATH, embedding_function=embedding_function)
    else:
        os.makedirs(CHROMA_PATH, exist_ok=True)
        db = Chroma(persist_directory=CHROMA_PATH, embedding_function=embedding_function)
    return db

# -------------- Th√™m d·ªØ li·ªáu v√†o ChromaDB -------------- #
def add_to_chroma(chunks):
    db = create_or_get_vectorstore()
    db.add_documents(chunks)
    db.persist()
    return len(chunks)

# -------------- T√¨m ki·∫øm v·ªõi Chroma -------------- #
def search_with_chroma(query):
    db = create_or_get_vectorstore()
    retriever = db.as_retriever(search_kwargs={"k": 2})
    results = retriever.get_relevant_documents(query)
    best_match = results[0].page_content if results else "Kh√¥ng t√¨m th·∫•y c√¢u tr·∫£ l·ªùi."
    return best_match

# -------------- X·ª≠ l√Ω d·ªçn d·∫πp an to√†n -------------- #
def safe_cleanup(directory):
    time.sleep(1)
    try:
        shutil.rmtree(directory)
    except PermissionError:
        for proc in psutil.process_iter(['pid', 'name']):
            if 'chroma' in proc.info['name'].lower():
                proc.kill()
        shutil.rmtree(directory)

# -------------- T√¨m ki·∫øm trong file PDF -------------- #
def search_from_pdf_file(pdf_file, query):
    # L∆∞u file PDF t·∫°m th·ªùi
    temp_dir = "temp"
    os.makedirs(temp_dir, exist_ok=True)
    temp_pdf_path = os.path.join(temp_dir, pdf_file.name)
    with open(temp_pdf_path, "wb") as f:
        f.write(pdf_file.getbuffer())

    # Load n·ªôi dung t·ª´ file PDF
    loader = PyPDFLoader(temp_pdf_path)
    docs = loader.load()
    chunks = split_documents(docs)

    # T·∫°o vectorstore t·∫°m th·ªùi trong th∆∞ m·ª•c ri√™ng (temp_chroma)
    temp_chroma_dir = "temp_chroma"
    if os.path.exists(temp_chroma_dir):
        shutil.rmtree(temp_chroma_dir)
    os.makedirs(temp_chroma_dir, exist_ok=True)

    embedding_function = get_embedding_function()
    temp_db = Chroma(persist_directory=temp_chroma_dir, embedding_function=embedding_function)
    temp_db.add_documents(chunks)
    temp_db.persist()

    # T√¨m ki·∫øm c√¢u tr·∫£ l·ªùi trong vectorstore t·∫°m th·ªùi
    retriever = temp_db.as_retriever(search_kwargs={"k": 2})
    results = retriever.get_relevant_documents(query)
    best_match = results[0].page_content if results else "Kh√¥ng t√¨m th·∫•y c√¢u tr·∫£ l·ªùi."

    # ƒê√≥ng k·∫øt n·ªëi v·ªõi database tr∆∞·ªõc khi x√≥a
    try:
        temp_db._client.close()  # ƒê√≥ng k·∫øt n·ªëi database
        temp_db = None  # Gi·∫£i ph√≥ng ƒë·ªëi t∆∞·ª£ng ChromaDB
        import gc
        gc.collect()
        shutil.rmtree(temp_chroma_dir)  # X√≥a th∆∞ m·ª•c t·∫°m
        os.remove(temp_pdf_path)  # X√≥a file PDF t·∫°m
    except Exception as e:
        print(f"L·ªói khi x√≥a t·ªáp ho·∫∑c th∆∞ m·ª•c: {e}")

    return best_match

# -------------- Giao di·ªán Streamlit -------------- #
st.set_page_config(page_title="RAG System", layout="wide")
st.title("CHATBOT RAG")

# Load d·ªØ li·ªáu t·ª´ th∆∞ m·ª•c data v√† file document.txt
documents = load_documents()
chunks = split_documents(documents)
num_added = add_to_chroma(chunks)
st.success(f"‚úÖ ƒê√£ n·∫°p {num_added} ƒëo·∫°n vƒÉn b·∫£n v√†o ChromaDB t·ª´ d·ªØ li·ªáu c√≥ s·∫µn!")

# H·ª£p nh·∫•t hai khung chat th√†nh m·ªôt
st.subheader("üí¨ H·ªèi t·ª´ d·ªØ li·ªáu hi·ªán c√≥ ho·∫∑c t·ª´ file PDF")
uploaded_pdf_query = st.file_uploader("üìÇ T·∫£i l√™n file PDF ƒë·ªÉ h·ªèi (n·∫øu c√≥):", type="pdf")
user_input = st.text_area("Nh·∫≠p c√¢u h·ªèi c·ªßa b·∫°n:", "B·∫°n mu·ªën h·ªèi g√¨?")

if st.button("Submit"):
    if uploaded_pdf_query:
        # N·∫øu c√≥ file PDF, t√¨m ki·∫øm trong file PDF
        pdf_result = search_from_pdf_file(uploaded_pdf_query, user_input)
        st.write("üí° **C√¢u tr·∫£ l·ªùi t·ª´ file PDF:**", pdf_result)
    else:
        # N·∫øu kh√¥ng c√≥ file PDF, t√¨m ki·∫øm trong d·ªØ li·ªáu hi·ªán c√≥ (bao g·ªìm c·∫£ document.txt)
        raw_result = search_with_chroma(user_input)
        st.write("üí° **C√¢u tr·∫£ l·ªùi:**", raw_result)
