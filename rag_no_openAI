import streamlit as st
import os
import shutil
import faiss
import numpy as np
from langchain_community.document_loaders import PyPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import Chroma
from langchain.embeddings import HuggingFaceEmbeddings

def get_embedding_function():
    return HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")



# Äá»‹nh nghÄ©a Ä‘Æ°á»ng dáº«n
CHROMA_PATH = "chroma"
DATA_PATH = "data"

# HÃ m lÆ°u file táº£i lÃªn
def save_uploaded_file(uploaded_file):
    if not os.path.exists(DATA_PATH):
        os.makedirs(DATA_PATH)
    file_path = os.path.join(DATA_PATH, uploaded_file.name)
    with open(file_path, "wb") as f:
        f.write(uploaded_file.getbuffer())
    return file_path

from langchain.docstore.document import Document

def load_documents():
    docs = []

    # Äá»c file TXT
    txt_file_path = r"D:\RAG Advance\data\documents.txt"  # ÄÆ°á»ng dáº«n tuyá»‡t Ä‘á»‘i
    if os.path.exists(txt_file_path):
        with open(txt_file_path, "r", encoding="utf-8") as f:
            content = f.read()
        docs.append(Document(page_content=content))

    # Äá»c táº¥t cáº£ cÃ¡c file PDF trong thÆ° má»¥c DATA_PATH
    for file in os.listdir(DATA_PATH):
        file_path = os.path.join(DATA_PATH, file)
        if file.endswith(".pdf"):
            loader = PyPDFLoader(file_path)
            docs.extend(loader.load())  # ThÃªm ná»™i dung PDF vÃ o danh sÃ¡ch docs

    return docs


def split_documents(documents):
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=256,    # KÃ­ch thÆ°á»›c vá»«a Ä‘á»§ Ä‘á»ƒ giá»¯ ngá»¯ cáº£nh
        chunk_overlap=50   # Chá»“ng láº¥n nháº¹ Ä‘á»ƒ Ä‘áº£m báº£o khÃ´ng máº¥t thÃ´ng tin
    )
    return text_splitter.split_documents(documents)


def add_to_chroma(chunks):
    db = Chroma(persist_directory=CHROMA_PATH, embedding_function=get_embedding_function())
    db.add_documents(chunks)
    db.persist()
    return len(chunks)

def search_with_faiss(query):
    db = Chroma(persist_directory=CHROMA_PATH, embedding_function=get_embedding_function())
    retriever = db.as_retriever(search_kwargs={"k": 2})
    results = retriever.get_relevant_documents(query)
    best_match = results[0].page_content if results else "KhÃ´ng tÃ¬m tháº¥y cÃ¢u tráº£ lá»i."
    
    return best_match
import re

def extract_year(text):
    match = re.search(r'\b(19\d{2}|20\d{2})\b', text) 
    return match.group(0) if match else "KhÃ´ng tÃ¬m tháº¥y nÄƒm"

    import re

def clean_response(text, query):
    sentences = text.split(". ")  # TÃ¡ch tá»«ng cÃ¢u
    relevant_sentences = [s for s in sentences if query.lower() in s.lower()]
    
    return ". ".join(relevant_sentences) if relevant_sentences else text  # Tráº£ vá» ná»™i dung liÃªn quan nháº¥t
    
    
# ============= Giao diá»‡n Streamlit =============
st.set_page_config(page_title="RAG System", layout="wide")

st.title("CHATBOT RAG")

# Khu vá»±c táº£i file
uploaded_file = st.file_uploader("ğŸ“‚ Upload your file:", type=["pdf", "txt"])
if uploaded_file:
    file_path = save_uploaded_file(uploaded_file)
    st.success(f"âœ… File '{uploaded_file.name}' Ä‘Ã£ Ä‘Æ°á»£c táº£i lÃªn!")

# NÃºt Load Data
if st.button("ğŸ”„ Load Data"):
    documents = load_documents()
    chunks = split_documents(documents)
    num_added = add_to_chroma(chunks)
    st.success(f"âœ… ÄÃ£ thÃªm {num_added} Ä‘oáº¡n vÄƒn báº£n vÃ o ChromaDB!")

# Khu vá»±c nháº­p cÃ¢u há»i
st.subheader("ğŸ’¬ Nháº­p cÃ¢u há»i:")
user_input = st.text_area("Enter text:", "Báº¡n muá»‘n há»i gÃ¬?")

if st.button("Submit"):
    raw_result = search_with_faiss(user_input)
    final_answer = clean_response(raw_result, user_input)
    st.write("ğŸ’¡ **CÃ¢u tráº£ lá»i:**", final_answer)
